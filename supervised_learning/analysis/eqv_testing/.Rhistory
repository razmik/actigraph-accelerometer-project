source("E:\Projects\test projects\R\start.R")
source("E:/Projects/test projects/R/start.R")
source("E:/Projects/test projects/R/start.R")
squares
dim(squares)
str(squares)
summary(squares)
?iris
q()
proj_folder = 'E:\University Documents\Lecture Notes\Predictive Analytics\R Workshop\R_Intro'
gsub('\','/', proj_folder)
fsdf
ad
)
''
'
gsub('\\','/', proj_folder)
proj_folder
gsub('\\','/', 'E:\University Documents\Lecture Notes\Predictive Analytics\R Workshop\R_Intro')
proj_folder = "E:\University Documents\Lecture Notes\Predictive Analytics\R Workshop\R_Intro"
proj_folder = "E:/University Document/Lecture Note/Predictive Analytics/R Workshop/R_Intro"
setwd(proj_folder)
setwd("E:/University Document/Lecture Note/Predictive Analytics/R Workshop/R_Intro")
tab = as.table(matrix(c(12, 33, 19,
38, 17, 31 ), nrow=2, byrow=TRUE))
tab
rownames(tab)        = c("PRIME", "PROTECT")
tab
colnames(tab) = c("RP", "EBRT", AS"")
colnames(tab) = c("RP", "EBRT", "AS")
tab
chisq.test(tab)
setwd("E:/Projects/accelerometer-project/analyze/time_in_pa_cat")
library(equivalence)
n = 110
percentage = 0.20
input_files <- list.files('output/preprocess/')
input_foldername <- 'output/preprocess/'
output_foldername <- 'output/tost/'
input_data <- read.csv(paste(input_foldername, input_files[0], sep=""), as.is=T)
paste(input_foldername, input_files[0], sep="")
read.csv(paste(input_foldername, input_files[0], sep=""), as.is=T)
read.csv("/output/preprocess/", as.is=T)
input_files
input_files[0]
input_data <- read.csv(paste(input_foldername, "hlr_mvpa_female.csv", sep=""), as.is=T)
print(mean(input_data$freedson,na.rm=T))
library(equivalence)
n = 110
percentage = 0.20
input_files <- list.files('output/preprocess/')
input_foldername <- 'output/preprocess/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(result)
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
library(equivalence)
n = 110
percentage = 0.20
input_files <- list.files('output/preprocess/')
input_foldername <- 'output/preprocess/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(file)
print(result)
print("\n\n")
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
library(equivalence)
n = 110
percentage = 0.20
input_files <- list.files('output/preprocess/')
input_foldername <- 'output/preprocess/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(file)
print(result)
print("")
print("")
print("")
print("")
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
library(equivalence)
n = 110
percentage = 0.20
input_files <- list.files('output/preprocess/hlr_mvpa/')
input_foldername <- 'output/preprocess/hlr_mvpa/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
n = nrow(input_data)
print(nrow)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(file)
print(result)
print("")
print("")
print("")
print("")
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
library(equivalence)
n = 110
percentage = 0.20
input_files <- list.files('output/preprocess/hlr_mvpa/')
input_foldername <- 'output/preprocess/hlr_mvpa/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
n = nrow(input_data)
print(n)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(file)
print(result)
print("")
print("")
print("")
print("")
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
library(equivalence)
percentage = 0.20
input_files <- list.files('output/preprocess/hlr_mvpa/')
input_foldername <- 'output/preprocess/hlr_mvpa/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
n = nrow(input_data)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(file)
print(result)
print("")
print("")
print("")
print("")
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
library(equivalence)
percentage = 0.05
input_files <- list.files('output/preprocess/silr_sb/')
input_foldername <- 'output/preprocess/silr_sb/'
output_foldername <- 'output/tost/'
for (file  in input_files) {
input_data <- read.csv(paste(input_foldername, file, sep=""), as.is=T)
freedson_mean = mean(input_data$freedson,na.rm=T)
predicting_mean = mean(input_data$predicting,na.rm=T)
n = nrow(input_data)
# calculations from summary statistics (group means and pooled sd)
# Note tost.stat() wants sd, not se
tost.stat(predicting_mean-freedson_mean, 0.19*sqrt(percentage*100), n, Epsilon=percentage*freedson_mean)
# arguments are the difference in group means, the pooled sd,
#   the sample size, and the +/- equivalence region
result <- with(input_data, tost(freedson, predicting, epsilon=percentage*freedson_mean, paired=T) )
print(file)
print(result)
print("")
print("")
print("")
print("")
#temp_name <- paste(output_foldername, paste(strsplit(file, '_FE.txt')[1], "_predicted_right_wrist_PAintensity_2017.csv", sep=""), sep="")
#write.csv(pred_Hip, temp_name)
#print(paste('predicted for right - ', file))
}
